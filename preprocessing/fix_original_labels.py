#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fix Original Dataset Labels and Re-balance

This script fixes emotion labels on the original full dataset (1000 samples)
and then creates a properly balanced dataset with correct labels.
"""

import pandas as pd
import numpy as np
import re
from collections import defaultdict
from datetime import datetime

class HindiUrduEmotionCorrector:
    """Corrects emotion labels for Hindi/Urdu text using linguistic analysis"""
    
    def __init__(self):
        # Define Hindi/Urdu emotion keywords
        self.negative_keywords = {
            # Sadness/Pain
            'рджрд░реНрдж', 'рдЧрдо', 'рд╕рджрдорд╛', 'рдЧрд╝рдо', 'рдЕрдлрд╝рд╕реЛрд╕', 'рдЖрдВрд╕реВ', 'рд░реБрд▓рд╛рдирд╛', 'рд░реЛрдирд╛', 'рддрдХрд▓реАрдл',
            'рдкрд░реЗрд╢рд╛рдиреА', 'рдбрд░', 'рдЦрд╝реМрдлрд╝', 'рдЪрд┐рдВрддрд╛', 'рдмреЗрдЪреИрдиреА', 'рдЙрджрд╛рд╕реА', 'рдЕрдХреЗрд▓рд╛рдкрди',
            # Separation/Loss
            'рдЬреБрджрд╛рдИ', 'рд╡рд┐рдЫреЛрд╣', 'рдмрд┐рдЫрдбрд╝рдирд╛', 'рдЦреЛрдирд╛', 'рдореМрдд', 'рдорд░рдирд╛', 'рдореГрддреНрдпреБ', 'рдЕрдВрдд',
            'рдЫреЛрдбрд╝рдирд╛', 'рддреНрдпрд╛рдЧрдирд╛', 'рднреВрд▓рдирд╛', 'рднреБрд▓рд╛рдирд╛', 'рджреВрд░', 'рдЕрд▓рдЧ',
            # Negative emotions
            'рдЧрд╝реБрд╕реНрд╕рд╛', 'рдХреНрд░реЛрдз', 'рдирдлрд╝рд░рдд', 'рдШреГрдгрд╛', 'рдИрд░реНрд╖реНрдпрд╛', 'рдЬрд▓рди', 'рд░рдВрдЬрд┐рд╢', 'рд╢рд┐рдХрд╛рдпрдд',
            'рдмрд░реНрдмрд╛рдж', 'рддрдмрд╛рд╣', 'рдирд╖реНрдЯ', 'рдЦрддреНрдо', 'рд╕рдорд╛рдкреНрдд', 'рдирд╛рдХрд╛рдо', 'рдЕрд╕рдлрд▓',
            # Pain words
            'рдЬрд╝рдЦреНрдо', 'рдШрд╛рд╡', 'рдЪреЛрдЯ', 'рдХрд╖реНрдЯ', 'рдкреАрдбрд╝рд╛', 'рд╡реНрдпрдерд╛', 'рд╕рдВрддрд╛рдк', 'рдпрд╛рддрдирд╛',
            # Broken heart
            'рдЯреВрдЯрд╛', 'рдмрд┐рдЦрд░рд╛', 'рд╢рд┐рдХрд╕реНрдд', 'рд╣рд╛рд░', 'рдирд┐рд░рд╛рд╢рд╛', 'рд╣рддрд╛рд╢рд╛', 'рдмреЗрдХрд╛рд░',
            # Additional negative words
            'рджреБрдЦреА', 'рдЙрджрд╛рд╕', 'рдкрд░реЗрд╢рд╛рди', 'рдмреЗрдЪреИрди', 'рдЪрд┐рдВрддрд┐рдд', 'рдбрд░рд╛', 'рднрдпрднреАрдд'
        }
        
        self.positive_keywords = {
            # Happiness/Joy
            'рдЦреБрд╢реА', 'рдкреНрд░рд╕рдиреНрди', 'рдЖрдирдВрдж', 'рд╣рд░реНрд╖', 'рдЙрд▓реНрд▓рд╛рд╕', 'рдорд╕реНрддреА', 'рдордЬрд╛', 'рдзрдиреНрдп',
            'рд╕реБрдЦреА', 'рд╕рдВрддреБрд╖реНрдЯ', 'рдкреНрд░рдлреБрд▓реНрд▓рд┐рдд', 'рд╣рдВрд╕рдирд╛', 'рдореБрд╕реНрдХрд╛рди', 'рдореБрд╕реНрдХреБрд░рд╛рдирд╛',
            # Love (positive context)
            'рдЦреБрд╢рд┐рдпрд╛рдВ', 'рдЬрд╢реНрди', 'рдордирд╛рдирд╛', 'рдЙрддреНрд╕рд╡', 'рддреНрдпреЛрд╣рд╛рд░', 'рд╕рдлрд▓', 'рдЬреАрдд', 'рд╡рд┐рдЬрдп',
            'рдХрд╛рдордпрд╛рдм', 'рд╕рдлрд▓рддрд╛', 'рдЙрдкрд▓рдмреНрдзрд┐', 'рдкреНрд░рд╛рдкреНрддрд┐', 'рдкреВрд░реНрдг', 'рд╕рдВрдкреВрд░реНрдг',
            # Hope/Optimism  
            'рдЙрдореНрдореАрдж', 'рдЖрд╢рд╛', 'рд╡рд┐рд╢реНрд╡рд╛рд╕', 'рднрд░реЛрд╕рд╛', 'рд╣реМрд╕рд▓рд╛', 'рд╕рд╛рд╣рд╕', 'рджрдо', 'рдЬреЛрд╢',
            'рдЙрддреНрд╕рд╛рд╣', 'рдЬреБрдиреВрди', 'рд╢реМрдХ', 'рдЪрд╛рд╣', 'рдЗрдЪреНрдЫрд╛', 'рдХрд╛рдордирд╛', 'рдЕрд░рдорд╛рди',
            # Additional positive words
            'рдкреНрд░реЗрдо', 'рд╕реНрдиреЗрд╣', 'рд╡рд╛рддреНрд╕рд▓реНрдп', 'рдХрд░реБрдгрд╛', 'рджрдпрд╛', 'рдХреГрдкрд╛'
        }
        
        self.neutral_keywords = {
            # Contemplation/Philosophy
            'рд╕реЛрдЪ', 'рд╡рд┐рдЪрд╛рд░', 'рдЪрд┐рдВрддрди', 'рдордирди', 'рд╕рдордЭ', 'рдмреБрджреНрдзрд┐', 'рдЬреНрдЮрд╛рди', 'рд╕рдордЭрджрд╛рд░реА',
            'рдпрд╛рдж', 'рд╕реНрдореГрддрд┐', 'рдпрд╛рджреЗрдВ', 'рдмреАрддрд╛', 'рд╕рдордп', 'рд╡рдХрд╝реНрдд', 'рдХрд╛рд▓', 'рдпреБрдЧ',
            # Neutral states
            'рд╢рд╛рдВрдд', 'рд╕реНрдерд┐рд░', 'рд╕рдВрдпрдо', 'рдзреИрд░реНрдп', 'рд╕рдмреНрд░', 'рдЗрдВрддрдЬрд╝рд╛рд░', 'рдкреНрд░рддреАрдХреНрд╖рд╛',
            'рд╕рд╛рдорд╛рдиреНрдп', 'рдЖрдо', 'рд╕рд╛рдзрд╛рд░рдг', 'рдирд┐рдпрдорд┐рдд', 'рд░реЛрдЬрд╝рд╛рдирд╛', 'рджреИрдирд┐рдХ'
        }
        
        # Context patterns that modify sentiment
        self.pain_love_patterns = [
            r'рджрд░реНрдж.*рдкреНрдпрд╛рд░', r'рдкреНрдпрд╛рд░.*рджрд░реНрдж', r'рдЗрд╢реНрдХрд╝.*рдЧрдо', r'рдореЛрд╣рдмреНрдмрдд.*рддрдХрд▓реАрдл',
            r'рджрд┐рд▓.*рдЯреВрдЯ', r'рджрд┐рд▓.*рджрд░реНрдж', r'рдЖрдВрд╕реВ.*рдкреНрдпрд╛рд░', r'рдЬрд╝рдЦреНрдо.*рдЗрд╢реНрдХрд╝',
            r'рдЧрдо.*рдореЛрд╣рдмреНрдмрдд', r'рддрдХрд▓реАрдл.*рдкреНрд░реЗрдо'
        ]
        
        self.positive_love_patterns = [
            r'рдЦреБрд╢.*рдкреНрдпрд╛рд░', r'рдкреНрдпрд╛рд░.*рдЦреБрд╢реА', r'рдореБрд╕реНрдХреБрд░рд╛рдирд╛.*рдкреНрдпрд╛рд░', r'рд╣рдВрд╕рдирд╛.*рдЗрд╢реНрдХрд╝',
            r'рдЖрдирдВрдж.*рдкреНрд░реЗрдо', r'рдЦреБрд╢рд┐рдпрд╛рдВ.*рдореЛрд╣рдмреНрдмрдд'
        ]
        
    def analyze_emotion_content(self, text):
        """Analyze emotion content using keyword matching and context"""
        text = str(text).lower()
        
        # Count emotion keywords
        negative_count = sum(1 for word in self.negative_keywords if word in text)
        positive_count = sum(1 for word in self.positive_keywords if word in text)
        neutral_count = sum(1 for word in self.neutral_keywords if word in text)
        
        # Check for pain+love patterns (typically negative)
        pain_love_found = any(re.search(pattern, text) for pattern in self.pain_love_patterns)
        positive_love_found = any(re.search(pattern, text) for pattern in self.positive_love_patterns)
        
        return {
            'negative_score': negative_count + (3 if pain_love_found else 0),  # Increased weight
            'positive_score': positive_count + (3 if positive_love_found else 0),  # Increased weight
            'neutral_score': neutral_count,
            'pain_love': pain_love_found,
            'positive_love': positive_love_found
        }
    
    def correct_emotion(self, text, current_emotion):
        """Correct the emotion label based on linguistic analysis"""
        analysis = self.analyze_emotion_content(text)
        
        # Strong negative indicators
        if analysis['negative_score'] >= 2 or analysis['pain_love']:
            return 'negative'
        
        # Strong positive indicators  
        elif analysis['positive_score'] >= 2 or analysis['positive_love']:
            return 'positive'
        
        # Mild sentiment
        elif analysis['negative_score'] > analysis['positive_score']:
            return 'negative'
        elif analysis['positive_score'] > analysis['negative_score']:
            return 'positive'
        
        # Default to neutral for ambiguous cases
        else:
            return 'neutral'

def fix_original_dataset():
    """Fix emotion labels on the original full dataset"""
    print("ЁЯФз FIXING ORIGINAL DATASET LABELS (1000 SAMPLES)")
    print("=" * 70)
    
    # Load the original dataset with emotions
    df = pd.read_excel('datasets/output_with_emotions.xlsx')
    print(f"ЁЯУВ Loaded original dataset: {df.shape[0]} samples")
    
    # Initialize corrector
    corrector = HindiUrduEmotionCorrector()
    
    # Analyze current labels
    print(f"\nЁЯУК ORIGINAL EMOTION DISTRIBUTION:")
    current_dist = df['emotion'].value_counts()
    for emotion, count in current_dist.items():
        percentage = (count / len(df)) * 100
        print(f"  {emotion}: {count} samples ({percentage:.1f}%)")
    
    # Correct emotions
    print(f"\nЁЯФз CORRECTING EMOTION LABELS...")
    corrected_emotions = []
    changes = defaultdict(int)
    
    for i, row in df.iterrows():
        original_emotion = row['emotion']
        corrected_emotion = corrector.correct_emotion(row['text'], original_emotion)
        corrected_emotions.append(corrected_emotion)
        
        if original_emotion != corrected_emotion:
            changes[f"{original_emotion} -> {corrected_emotion}"] += 1
    
    # Update dataframe
    df['emotion_corrected'] = corrected_emotions
    
    print(f"\nЁЯУИ CORRECTION SUMMARY:")
    total_changes = sum(changes.values())
    print(f"  Total changes: {total_changes}/{len(df)} ({total_changes/len(df)*100:.1f}%)")
    for change, count in changes.items():
        print(f"  {change}: {count} changes")
    
    # Show new distribution
    print(f"\nЁЯУК CORRECTED EMOTION DISTRIBUTION:")
    new_dist = df['emotion_corrected'].value_counts()
    for emotion, count in new_dist.items():
        percentage = (count / len(df)) * 100
        print(f"  {emotion}: {count} samples ({percentage:.1f}%)")
    
    # Save corrected full dataset
    output_file = 'datasets/output_with_emotions_corrected_full.xlsx'
    df_corrected = df[['text', 'emotion_corrected']].copy()
    df_corrected.columns = ['text', 'emotion']
    df_corrected.to_excel(output_file, index=False)
    
    print(f"\nЁЯТ╛ SAVED CORRECTED FULL DATASET:")
    print(f"  File: {output_file}")
    print(f"  Shape: {df_corrected.shape}")
    
    return df_corrected, changes

def balance_corrected_dataset(df_corrected):
    """Balance the corrected dataset properly"""
    print(f"\n\nЁЯФД BALANCING CORRECTED DATASET")
    print("=" * 70)
    
    # Get emotion counts
    emotion_counts = df_corrected['emotion'].value_counts()
    print(f"ЁЯУК CORRECTED DISTRIBUTION BEFORE BALANCING:")
    for emotion, count in emotion_counts.items():
        percentage = (count / len(df_corrected)) * 100
        print(f"  {emotion}: {count} samples ({percentage:.1f}%)")
    
    # Find minimum class size for balancing
    min_samples = emotion_counts.min()
    print(f"\nтЪЦя╕П BALANCING STRATEGY:")
    print(f"  Minimum class size: {min_samples}")
    print(f"  Balancing method: Undersample to {min_samples} per class")
    
    # Balance by undersampling
    balanced_dfs = []
    for emotion in emotion_counts.index:
        emotion_df = df_corrected[df_corrected['emotion'] == emotion]
        if len(emotion_df) > min_samples:
            # Undersample
            emotion_balanced = emotion_df.sample(n=min_samples, random_state=42)
            print(f"  {emotion}: {len(emotion_df)} -> {len(emotion_balanced)} (undersampled)")
        else:
            emotion_balanced = emotion_df
            print(f"  {emotion}: {len(emotion_df)} -> {len(emotion_balanced)} (no change)")
        
        balanced_dfs.append(emotion_balanced)
    
    # Combine balanced data
    df_balanced = pd.concat(balanced_dfs, ignore_index=True)
    
    # Shuffle the dataset
    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)
    
    print(f"\nЁЯУК FINAL BALANCED DISTRIBUTION:")
    final_dist = df_balanced['emotion'].value_counts()
    for emotion, count in final_dist.items():
        percentage = (count / len(df_balanced)) * 100
        print(f"  {emotion}: {count} samples ({percentage:.1f}%)")
    
    print(f"\nЁЯУИ BALANCING SUMMARY:")
    print(f"  Original size: {len(df_corrected)} samples")
    print(f"  Balanced size: {len(df_balanced)} samples")
    print(f"  Reduction: {len(df_corrected) - len(df_balanced)} samples")
    
    # Save balanced dataset
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f'datasets/output_with_emotions_corrected_balanced_{timestamp}.xlsx'
    df_balanced.to_excel(output_file, index=False)
    
    print(f"\nЁЯТ╛ SAVED CORRECTED & BALANCED DATASET:")
    print(f"  File: {output_file}")
    print(f"  Shape: {df_balanced.shape}")
    print(f"  Ready for model training!")
    
    return df_balanced, output_file

def show_correction_examples(df_original, df_corrected):
    """Show examples of the corrections made"""
    print(f"\n\nЁЯУЭ EXAMPLES OF MAJOR CORRECTIONS:")
    print("=" * 70)
    
    # Find samples where corrections were made
    df_with_original = df_original.copy()
    df_with_original['emotion_corrected'] = df_corrected['emotion']
    
    corrected_samples = df_with_original[df_with_original['emotion'] != df_with_original['emotion_corrected']]
    
    # Show examples by correction type
    correction_types = corrected_samples.groupby(['emotion', 'emotion_corrected']).size().sort_values(ascending=False)
    
    for (orig, corr), count in correction_types.head(5).items():
        print(f"\nЁЯФД {orig.upper()} -> {corr.upper()} ({count} corrections):")
        examples = corrected_samples[(corrected_samples['emotion'] == orig) & 
                                   (corrected_samples['emotion_corrected'] == corr)].head(3)
        
        for i, row in examples.iterrows():
            print(f"  ЁЯУД {row['text'][:120]}...")
            
            # Show analysis
            corrector = HindiUrduEmotionCorrector()
            analysis = corrector.analyze_emotion_content(row['text'])
            print(f"     Analysis: neg={analysis['negative_score']}, pos={analysis['positive_score']}, neu={analysis['neutral_score']}")
            if analysis['pain_love']:
                print(f"     ЁЯТФ Contains pain+love pattern")
            if analysis['positive_love']:
                print(f"     ЁЯТХ Contains positive+love pattern")
            print()

def main():
    """Main function to fix and balance the dataset"""
    print("ЁЯЪА EMOTION DATASET CORRECTION & BALANCING PIPELINE")
    print("=" * 70)
    
    # Step 1: Fix original dataset labels
    df_corrected_full, correction_stats = fix_original_dataset()
    
    # Step 2: Balance the corrected dataset
    df_balanced, balanced_file = balance_corrected_dataset(df_corrected_full)
    
    # Step 3: Show correction examples
    df_original = pd.read_excel('datasets/output_with_emotions.xlsx')
    show_correction_examples(df_original, df_corrected_full)
    
    print(f"\nтЬЕ PIPELINE COMPLETE!")
    print(f"ЁЯУБ Corrected full dataset: datasets/output_with_emotions_corrected_full.xlsx")
    print(f"ЁЯУБ Corrected balanced dataset: {balanced_file}")
    print(f"ЁЯОп Ready to retrain all models with proper labels!")
    
    return balanced_file

if __name__ == "__main__":
    balanced_dataset_file = main() 